# LLM-papers

A repo lists papers about LLM.

---

- In-Context Learning
	- [2023/05/28] *Mitigating Label Biases for In-context Learning* | [[paper]](https://arxiv.org/abs/2305.19148) | [code]
	
  - [2023/05/16] *What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning* | [[paper]](https://arxiv.org/abs/2305.09731) | [[code]](https://github.com/princeton-nlp/WhatICLLearns)
	
  - [2021/02/19] *Calibrate Before Use: Improving Few-Shot Performance of Language Models* | [[paper]](https://arxiv.org/abs/2102.09690) | [[code]](https://www.github.com/tonyzhaozh/few-shot-learning) 



---
- Instruction-Tuning
	- [2023/05/25] *The False Promise of Imitating Proprietary LLMs* | [[paper]](https://arxiv.org/abs/2305.15717) | [code]
	
  - [2023/05/18] *LIMA: Less Is More for Alignment* | [[paper]](https://arxiv.org/abs/2305.11206) | [code]

  - [2023/04/24] *WizardLM: Empowering Large Language Models to Follow Complex Instructions* | [[paper]](https://arxiv.org/abs/2304.12244) | [[code]](https://github.com/nlpxucan/WizardLM)


---
- Alignment
	- [2023/05/17] *SLiC-HF: Sequence Likelihood Calibration with Human Feedback* | [[paper]](https://arxiv.org/abs/2305.10425) | [code]
	
  - [2023/04/11] *RRHF: Rank Responses to Align Language Models with Human Feedback without tears* | [[paper]](https://arxiv.org/abs/2304.05302) | [[code]](https://github.com/GanjinZero/RRHF)
  
  - [2022/03/31] *BRIO: Bringing Order to Abstractive Summarization* | [[paper]](https://arxiv.org/abs/2203.16804) | [[code]](https://github.com/yixinL7/BRIO)

